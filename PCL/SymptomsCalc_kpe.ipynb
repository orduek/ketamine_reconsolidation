{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "meDat = pd.read_csv('/home/or/kpe_task_analysis/task_based_analysis/kpe_sub_condition.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allDat = pd.read_csv('/home/or/Documents/kpe_analyses/KPEIHR0009_DATA_2020-08-31_1301.csv')\n",
    "pclDat = allDat.filter(like='pcl5')\n",
    "# remove two irrelevant vars\n",
    "del pclDat['pcl5_complete']\n",
    "del pclDat['pcl5_total']\n",
    "# sum all pcl scores\n",
    "a = pclDat.sum(axis = 1, skipna = True) \n",
    "# add a to df\n",
    "pclDat.insert(20, \"pcl_total\", a)\n",
    "pclDat.insert(0, \"scr_id\", allDat['scr_id'])\n",
    "pclDat.insert(1, \"redcap_event_name\", allDat[\"redcap_event_name\"])\n",
    "newPclDat = pclDat[((pclDat['redcap_event_name'] == 'screening_selfrepo_arm_1') | \n",
    "                    (pclDat['redcap_event_name'] == 'visit_1_arm_1') | \n",
    "                    #(pclDat['redcap_event_name'] == 'visit_2_infusion_s_arm_1') | \n",
    "                    (pclDat['redcap_event_name'] == 'visit_7_week_follo_arm_1') | \n",
    "                    (pclDat['redcap_event_name'] == '30_day_follow_up_s_arm_1') | \n",
    "                    (pclDat['redcap_event_name'] == '90_day_follow_up_s_arm_1'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPclDat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove space from scr_id\n",
    "newPclDat['scr_id'] = newPclDat['scr_id'].str.replace(\" \",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widePclDat = newPclDat.pivot(index='scr_id', columns='redcap_event_name', values='pcl_total')\n",
    "widePclDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all NAs in visit7\n",
    "PclDat_nonNa = widePclDat.dropna(subset=['visit_7_week_follo_arm_1'])\n",
    "# check if there is a 0 and change to NaN\n",
    "#\n",
    "PclDat_nonNa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "# merging datasets to have medical conditions also\n",
    "fullPCL = PclDat_nonNa.merge(meDat, left_on='scr_id', right_on='scr_id', how='outer')\n",
    "\n",
    "# rename\n",
    "fullPCL = fullPCL.rename(columns={\"30_day_follow_up_s_arm_1\": \"30_days\", \"90_day_follow_up_s_arm_1\": \"90_days\",\n",
    "                   \"screening_selfrepo_arm_1\":\"screening\", \n",
    "                   \"visit_1_arm_1\" : \"visit_1\",\n",
    "                   \"visit_7_week_follo_arm_1\" : \"visit_7\"\n",
    "                  })\n",
    "\n",
    "# reorder columns\n",
    "colOrder = ['scr_id','med_cond','screening','visit_1','visit_7','30_days', '90_days']\n",
    "fullPCL = fullPCL[colOrder]\n",
    "fullPCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace visit 1 missing values or zeroes with screening scores\n",
    "#df.loc[df.ID == 103, 'FirstName'] = \"Matt\"\n",
    "fullPCL.loc[fullPCL.scr_id=='KPE1339','visit_1'] = fullPCL.loc[fullPCL.scr_id=='KPE1339'].screening\n",
    "fullPCL.loc[fullPCL.scr_id=='KPE1390','visit_1'] = fullPCL.loc[fullPCL.scr_id=='KPE1390'].screening\n",
    "fullPCL.loc[fullPCL.scr_id=='KPE1464','visit_1'] = fullPCL.loc[fullPCL.scr_id=='KPE1464'].screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPCL = fullPCL[['scr_id','med_cond','visit_1','visit_7','30_days', '90_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPCL_melt = pd.melt(fullPCL, id_vars=['scr_id','med_cond'], var_name = 'time', value_name='pcl')\n",
    "fullPCL_melt[\"time\"] = fullPCL_melt.time.astype('category')\n",
    "# save as csv\n",
    "fullPCL_melt.to_csv('fullPCL_melt.csv', index = False)\n",
    "fullPCL.to_csv('fullPCL.csv', index = False)\n",
    "fullPCL_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPCL = fullPCL.rename(columns={\"30_days\":\"FollowUp_30\", \"90_days\": \"FollowUp90\",\n",
    "                   \"visit_1\": \"Before_Treatmeant\",\n",
    "                   \"visit_7\": \"After_Treatment\"\n",
    "                  })\n",
    "fullPCL_melt = pd.melt(fullPCL, id_vars=['scr_id','med_cond'], var_name = 'time', value_name='pcl')\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Changes in PCL scores\")\n",
    "g1 = sns.boxplot(x='time',y='pcl', data=fullPCL_melt, showfliers = False)\n",
    "sns.stripplot(x='time',y='pcl',hue='med_cond', data=fullPCL_melt, alpha=0.8, size=7)\n",
    "plt.hlines(y = 33, xmin = -0.5, xmax=3.5, color=\"blue\", linestyles=\"dashed\")\n",
    "g1.set_xlabel(\"\")\n",
    "g1.set_xticklabels([\"Before Treatment\", 'After Treatment', '30 Days Follow-Up', '90 Days Follow-Up'],\n",
    "                  fontsize = 14)\n",
    "g1.set_ylabel(\"Symptoms (PCL-5 Score)\", fontsize = 14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullPCL[['med_cond', 'visit_7',  '90_days']].groupby('med_cond').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "# px.strip(x='time', y='pcl', \n",
    "       #    data_frame=fullPCL_melt, color='med_cond')\n",
    "px.box(x='time', y='pcl',\n",
    "           data_frame=fullPCL_melt, color='med_cond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x='time', y='pcl', facet_col= 'med_cond', \n",
    "           data_frame=fullPCL_melt, color='scr_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slope for each subject\n",
    "changeDat = fullPCL[['scr_id','med_cond','visit_1','visit_7','30_days','90_days']]\n",
    "changeDat['beforeTrt'] = changeDat.visit_1- changeDat.visit_1\n",
    "changeDat['afterTrt'] = changeDat.visit_7- changeDat.visit_1\n",
    "changeDat['monthFU'] = changeDat['30_days']- changeDat.visit_1\n",
    "changeDat['ThreeMonths'] = changeDat['90_days'] - changeDat.visit_1\n",
    "\n",
    "changeDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeDat[['scr_id', 'med_cond','afterTrt', 'monthFU','ThreeMonths']].groupby(['med_cond']).describe(percentiles=[0.025,0.975]) # count how many in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['scr_id', 'med_cond','beforeTrt','afterTrt','monthFU', 'ThreeMonths']\n",
    "changeDat_melt = pd.melt(changeDat[columns], \n",
    "                id_vars=['scr_id','med_cond'], \n",
    "                         var_name = 'time', value_name='pcl')\n",
    "changeDat_melt.head()\n",
    "#changeDat_melt.to_csv('changeMelt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.line(x='time', y='pcl', facet_col= 'med_cond', \n",
    "           data_frame=changeDat_melt, color='scr_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeDat_melt['time'] = changeDat_melt.time.astype('category')\n",
    "data = changeDat_melt[changeDat_melt.time!='beforeTrt']\n",
    "data.to_csv('meltedPCL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple linear regression of time * pcl (no random effect)\n",
    "import pymc3 as pm\n",
    "from pymc3.glm import GLM\n",
    "\n",
    "with pm.Model() as model_glm:\n",
    "    GLM.from_formula('pcl ~ time', data = changeDat_melt)\n",
    "    trace = pm.sample(draws=2000, tune=2000, cores=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use actual values and not delta\n",
    "import numpy as np\n",
    "fullPCL_melt['scr_id'] = fullPCL_melt.scr_id.astype('category')\n",
    "n_subs = len(np.unique(fullPCL_melt.scr_id))\n",
    "fullPCL_melt.time = pd.Categorical(fullPCL_melt.time, \n",
    "                    categories=['visit_1','visit_7','30_days', '90_days'])\n",
    "timeIDX = fullPCL_melt.time.cat.codes.values\n",
    "#fullPCL_melt\n",
    "print(timeIDX)\n",
    "#fullPCL_melt\n",
    "fullPCL_melt.med_cond = fullPCL_melt.med_cond.astype('category')\n",
    "medIDX = fullPCL_melt.med_cond.cat.codes.values\n",
    "medIDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPCL[['med_cond', 'visit_7', '30_days']].groupby('med_cond').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilevel model with reparametarization\n",
    "# the offset specification is taken from https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/\n",
    "with pm.Model() as multilevel_real:\n",
    "    # Hyperpriors for group nodes\n",
    "    sigma_a = pm.HalfCauchy('sigma_a', 5)\n",
    "    mu_a = pm.Normal('mu_a', mu=0, sd=20)\n",
    "    mu_b = pm.Normal('mu_b', mu=0, sd=20)\n",
    "    sigma_b = pm.HalfCauchy('sigma_b', 5)\n",
    "\n",
    "   \n",
    "   # a_offset = pm.Normal('a_offset', mu=0, sd=1, shape=n_subs)\n",
    "    #a = pm.Deterministic('a', mu_a + a_offset * sigma_a)\n",
    "    a = pm.Normal('a', mu=20, sd=20, shape=n_subs)\n",
    "    #z = pm.Normal('z', mu = 0, sigma = 1, shape = n_subs)\n",
    "       \n",
    "    b = pm.Normal('b', mu=0, sd=20, shape=4)\n",
    "    # b_offset = pm.Normal('b_offset', mu=0, sd=1 , shape = 4)\n",
    "    #b = pm.Deterministic('b', mu_b + b_offset * sigma_b)   \n",
    "    inter = pm.Normal('inter', mu=0, sd=5) # modeling interaction for each treatment\n",
    "    # set another prior to the group (i..e medication condition)\n",
    "    \n",
    "    bMed = pm.Normal('bMed', mu=0, sd=20, shape=2)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "\n",
    "    y_hat = a[sub_idx] + b[timeIDX]*timeIDX + bMed[medIDX]*fullPCL_melt.med_cond + inter*timeIDX*medIDX\n",
    "\n",
    "    # Data likelihood\n",
    "    likelihood = pm.Normal('likelihood', mu=y_hat,\n",
    "                           sigma=eps, observed=fullPCL_melt.pcl)\n",
    "    real_trace = pm.sample(4000, tune=2000, target_accept=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "print(pm.waic(real_trace))\n",
    "pm.summary(real_trace, credible_interval=.95, round_to=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(real_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## these results lookd like the lme4 results in R\n",
    "# lets run WAIC\n",
    "pm.stats.waic(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random effect Bayesian model for symptoms\n",
    "import numpy as np\n",
    "# set data\n",
    "# set indexing for subjects\n",
    "changeDat_melt['scr_id'] = changeDat_melt.scr_id.astype('category')\n",
    "sub_idx = changeDat_melt.scr_id.cat.codes.values # get county category index values (613 x 1) vec with nums [0-7]\n",
    "print(sub_idx)\n",
    "# set y observerd\n",
    "y_obs = changeDat_melt.pcl.values\n",
    "#print(data.pcl)\n",
    "n_subs = len(np.unique(changeDat_melt.scr_id))\n",
    "print(n_subs)\n",
    "# set time as index also\n",
    "# set only three categories (after, 1month, 3months)\n",
    "changeDat_melt.time = pd.Categorical(changeDat_melt.time, \n",
    "                    categories=['beforeTrt','afterTrt','monthFU', 'ThreeMonths'])\n",
    "timeIDX = changeDat_melt.time.cat.codes.values\n",
    "print(timeIDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model just uses the time as main effect (no checking per timepoint)\n",
    "# So similar to simple mixed models with subjects as the only random effect\n",
    "with pm.Model() as hierarchical_model:\n",
    "  \n",
    "    a = pm.Normal('a', mu=0, sd=20, shape=n_subs)\n",
    "    # Intercept for each timepoint, distributed around group mean mu_a\n",
    "    b = pm.Normal('b', mu=0, sd=20)\n",
    "    \n",
    "    # set another prior to the group (i..e medication condition)\n",
    "    bMed = pm.Normal('bMed', mu=0, sd=20)\n",
    "   \n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "\n",
    "    y_hat = a[sub_idx] + b*timeIDX + bMed*fullPCL_melt.med_cond \n",
    "\n",
    "    # Data likelihood\n",
    "    likelihood = pm.Normal('likelihood', mu=y_hat,\n",
    "                           sigma=eps, observed=fullPCL_melt.pcl)\n",
    "    hierarchical_trace = pm.sample(4000, tune=2000, target_accept=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm.stats.waic(hierarchical_trace))\n",
    "pm.summary(hierarchical_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(hierarchical_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilevel model with reparametarization\n",
    "with pm.Model() as multiLevel_repar:\n",
    "    # Hyperpriors for group nodes\n",
    "\n",
    "    sigma_a = pm.HalfNormal('sigma_a', 5.)\n",
    "\n",
    "    a = pm.Normal('a', mu=0, sigma=10)\n",
    "    z = pm.Normal('z', mu = 0, sigma = 1, shape = n_subs)\n",
    "    \n",
    "    \n",
    "    mu_b = pm.Normal('mu_b', mu=0, sigma=5)\n",
    "    b = pm.Normal('b', mu=mu_b, sigma=5,shape=4)\n",
    "    # set another prior to the group (i..e medication condition)\n",
    "    \n",
    "    bMed = pm.Normal('bMed', mu=0, sigma=10)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "\n",
    "    y_hat = a + z[sub_idx]*sigma_a + b[timeIDX]*timeIDX + bMed*changeDat_melt.med_cond \n",
    "\n",
    "    # Data likelihood\n",
    "    likelihood = pm.Normal('likelihood', mu=y_hat,\n",
    "                           sigma=eps, observed=changeDat_melt.pcl)\n",
    "    multiLevel_trace = pm.sample(4000, tune=2000, target_accept=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(multiLevel_trace, credible_interval=.95)\n",
    "#pm.model_to_graphviz(multiLevel_repar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as prior_GLMmodel:\n",
    "    a = pm.Normal('a', mu=0, sigma=10)#, shape=4)\n",
    "    # Intercept for each timepoint, distributed around group mean mu_a\n",
    "    b = pm.Normal('b', mu=0, sigma=10, shape=4)\n",
    "    \n",
    "    # set another prior to the group (i..e medication condition)\n",
    "    bMed = pm.Normal('bMed', mu=0, sigma=5)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "\n",
    "    y_hat = a + b[timeIDX]*timeIDX + bMed*changeDat_melt.med_cond \n",
    "\n",
    "    # Data likelihood\n",
    "    likelihood = pm.Normal('likelihood', mu=y_hat,\n",
    "                           sigma=eps, observed=changeDat_melt.pcl)\n",
    "    \n",
    "    priorGLM_trace = pm.sample(4000, tune=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(priorGLM_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    hierarchical_trace = pm.sample(4000, tune=2000, target_accept=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(hierarchical_trace, round_to=2, credible_interval=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using intercept as random variable\n",
    "- using the subjects as different intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pm.waic(hierarchical_trace, hierarchical_model)\n",
    "g = pm.waic(trace, model_glm)\n",
    "print(p)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.compare({'hierarchical': hierarchical_trace, 'glm': trace, 'priorGLM': priorGLM_trace,\n",
    "           'multilevel':multiLevel_trace})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LOO\n",
    "df_comp_LOO = pm.compare({'hierarchical': hierarchical_trace, 'glm': trace,\n",
    "                         'priorGLM': priorGLM_trace, 'multilevel':multiLevel_trace}\n",
    "                         , ic='LOO')\n",
    "df_comp_LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_compare(df_comp_LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.forestplot(trace, var_names=[], credible_interval=.95)\n",
    "g1 = pm.plot_forest(hierarchical_trace,  credible_interval=.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build nice dataframe from the statistical model for plotting\n",
    "\n",
    "dfStats = pd.DataFrame({'beforeTreatment': multiLevel_trace['b'][-1000:,0],\n",
    "                       'afterTreatment':multiLevel_trace['b'][-1000:,1],\n",
    "                       'One-Month_FollowUp': multiLevel_trace['b'][-1000:,2],\n",
    "                       'Three-Month_FulloUp': multiLevel_trace['b'][-1000:,3]})\n",
    "\n",
    "# melt it\n",
    "dfStats_melt = pd.melt(dfStats, var_name = 'time', value_name='pcl')\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Changes in PCL scores\")\n",
    "g1 = sns.boxplot(x='time',y='pcl', data=dfStats_melt, showfliers = False)\n",
    "g1.set_xlabel(\"\")\n",
    "g1.set_xticklabels([\"Before Treatment\", 'After Treatment', '30 Days Follow-Up', '90 Days Follow-Up'],\n",
    "                  fontsize = 14)\n",
    "g1.set_ylabel(\"Symptoms (PCL-5 Score)\", fontsize = 14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so, the best model is the one that takes different times, but from same distribution.  not the general one and not one that takes time as constant (obviously)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab demographic information (sex, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(allDat.columns)) # listing all variables in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
